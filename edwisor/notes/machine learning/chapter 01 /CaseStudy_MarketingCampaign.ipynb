{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fancyimpute import KNN   \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "import seaborn as sns\n",
    "from random import randrange, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([55., nan, 42., ..., 27., 51., 38.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('/Users/maneeshagvs/documents/datasets')\n",
    "\n",
    "os.getcwd()\n",
    "\n",
    "np.float64(marketing_train['custAge'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "marketing_train = pd.read_csv(\"marketing_tr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploratory Data Analysis\n",
    "marketing_train['schooling'] = marketing_train['schooling'].replace(\"illiterate\", \"unknown\")\n",
    "marketing_train['schooling'] = marketing_train['schooling'].replace([\"basic.4y\",\"basic.6y\",\"basic.9y\",\"high.school\",\"professional.course\"], \"high.school\")\n",
    "marketing_train['default'] = marketing_train['default'].replace(\"yes\", \"unknown\")\n",
    "marketing_train['marital'] = marketing_train['marital'].replace(\"unknown\", \"married\")\n",
    "marketing_train['month'] = marketing_train['month'].replace([\"sep\",\"oct\",\"mar\",\"dec\"], \"dec\")\n",
    "marketing_train['month'] = marketing_train['month'].replace([\"aug\",\"jul\",\"jun\",\"may\",\"nov\"], \"jun\")\n",
    "marketing_train['loan'] = marketing_train['loan'].replace(\"unknown\", \"no\")\n",
    "marketing_train['profession'] = marketing_train['profession'].replace([\"management\",\"unknown\",\"unemployed\",\"admin.\"], \"admin.\")\n",
    "marketing_train['profession'] = marketing_train['profession'].replace([\"blue-collar\",\"housemaid\",\"services\",\"self-employed\",\"entrepreneur\",\"technician\"], \"blue-collar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Value Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe with missing percentage\n",
    "missing_val = pd.DataFrame(marketing_train.isnull().sum())\n",
    "\n",
    "#Reset index\n",
    "missing_val = missing_val.reset_index()\n",
    "\n",
    "#Rename variable\n",
    "missing_val = missing_val.rename(columns = {'index': 'Variables', 0: 'Missing_percentage'})\n",
    "\n",
    "#Calculate percentage\n",
    "missing_val['Missing_percentage'] = (missing_val['Missing_percentage']/len(marketing_train))*100\n",
    "\n",
    "#descending order\n",
    "missing_val = missing_val.sort_values('Missing_percentage', ascending = False).reset_index(drop = True)\n",
    "\n",
    "#save output results \n",
    "missing_val.to_csv(\"Miising_perc.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5610.000000\n",
       "mean       40.009804\n",
       "std        10.574616\n",
       "min        18.000000\n",
       "25%        32.000000\n",
       "50%        38.000000\n",
       "75%        47.000000\n",
       "max        94.000000\n",
       "Name: custAge, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imputation method\n",
    "#Actual value = 29\n",
    "#Mean = 40.01\n",
    "#Median = 38\n",
    "#KNN = 29.35\n",
    "\n",
    "#create missing value\n",
    "#marketing_train['custAge'].loc[70] = np.nan\n",
    "\n",
    "\n",
    "marketing_train['custAge'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute with mean\n",
    "#marketing_train['custAge'] = marketing_train['custAge'].fillna(marketing_train['custAge'].mean())\n",
    "\n",
    "#Impute with median\n",
    "#marketing_train['custAge'] = marketing_train['custAge'].fillna(marketing_train['custAge'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN imputation\n",
    "#Assigning levels to the categories\n",
    "lis = []\n",
    "for i in range(0, marketing_train.shape[1]):\n",
    "    #print(i)\n",
    "    if(marketing_train.iloc[:,i].dtypes == 'object'):\n",
    "        marketing_train.iloc[:,i] = pd.Categorical(marketing_train.iloc[:,i])\n",
    "        #print(marketing_train[[i]])\n",
    "        marketing_train.iloc[:,i] = marketing_train.iloc[:,i].cat.codes \n",
    "        marketing_train.iloc[:,i] = marketing_train.iloc[:,i].astype('object')\n",
    "        \n",
    "        lis.append(marketing_train.columns[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace -1 with NA to impute\n",
    "for i in range(0, marketing_train.shape[1]):\n",
    "    marketing_train.iloc[:,i] = marketing_train.iloc[:,i].replace(-1, np.nan) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/fancyimpute/solver.py:58: UserWarning: Input matrix is not missing any values\n",
      "  warnings.warn(\"Input matrix is not missing any values\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing row 1/7414 with 0 missing, elapsed time: 12.506\n",
      "Imputing row 101/7414 with 0 missing, elapsed time: 12.507\n",
      "Imputing row 201/7414 with 0 missing, elapsed time: 12.507\n",
      "Imputing row 301/7414 with 0 missing, elapsed time: 12.508\n",
      "Imputing row 401/7414 with 0 missing, elapsed time: 12.508\n",
      "Imputing row 501/7414 with 0 missing, elapsed time: 12.508\n",
      "Imputing row 601/7414 with 0 missing, elapsed time: 12.508\n",
      "Imputing row 701/7414 with 0 missing, elapsed time: 12.509\n",
      "Imputing row 801/7414 with 0 missing, elapsed time: 12.509\n",
      "Imputing row 901/7414 with 0 missing, elapsed time: 12.509\n",
      "Imputing row 1001/7414 with 0 missing, elapsed time: 12.510\n",
      "Imputing row 1101/7414 with 0 missing, elapsed time: 12.510\n",
      "Imputing row 1201/7414 with 0 missing, elapsed time: 12.510\n",
      "Imputing row 1301/7414 with 0 missing, elapsed time: 12.511\n",
      "Imputing row 1401/7414 with 0 missing, elapsed time: 12.511\n",
      "Imputing row 1501/7414 with 0 missing, elapsed time: 12.511\n",
      "Imputing row 1601/7414 with 0 missing, elapsed time: 12.511\n",
      "Imputing row 1701/7414 with 0 missing, elapsed time: 12.512\n",
      "Imputing row 1801/7414 with 0 missing, elapsed time: 12.512\n",
      "Imputing row 1901/7414 with 0 missing, elapsed time: 12.512\n",
      "Imputing row 2001/7414 with 0 missing, elapsed time: 12.513\n",
      "Imputing row 2101/7414 with 0 missing, elapsed time: 12.513\n",
      "Imputing row 2201/7414 with 0 missing, elapsed time: 12.513\n",
      "Imputing row 2301/7414 with 0 missing, elapsed time: 12.514\n",
      "Imputing row 2401/7414 with 0 missing, elapsed time: 12.514\n",
      "Imputing row 2501/7414 with 0 missing, elapsed time: 12.514\n",
      "Imputing row 2601/7414 with 0 missing, elapsed time: 12.514\n",
      "Imputing row 2701/7414 with 0 missing, elapsed time: 12.515\n",
      "Imputing row 2801/7414 with 0 missing, elapsed time: 12.515\n",
      "Imputing row 2901/7414 with 0 missing, elapsed time: 12.515\n",
      "Imputing row 3001/7414 with 0 missing, elapsed time: 12.516\n",
      "Imputing row 3101/7414 with 0 missing, elapsed time: 12.516\n",
      "Imputing row 3201/7414 with 0 missing, elapsed time: 12.516\n",
      "Imputing row 3301/7414 with 0 missing, elapsed time: 12.517\n",
      "Imputing row 3401/7414 with 0 missing, elapsed time: 12.517\n",
      "Imputing row 3501/7414 with 0 missing, elapsed time: 12.517\n",
      "Imputing row 3601/7414 with 0 missing, elapsed time: 12.517\n",
      "Imputing row 3701/7414 with 0 missing, elapsed time: 12.518\n",
      "Imputing row 3801/7414 with 0 missing, elapsed time: 12.518\n",
      "Imputing row 3901/7414 with 0 missing, elapsed time: 12.518\n",
      "Imputing row 4001/7414 with 0 missing, elapsed time: 12.519\n",
      "Imputing row 4101/7414 with 0 missing, elapsed time: 12.519\n",
      "Imputing row 4201/7414 with 0 missing, elapsed time: 12.519\n",
      "Imputing row 4301/7414 with 0 missing, elapsed time: 12.521\n",
      "Imputing row 4401/7414 with 0 missing, elapsed time: 12.521\n",
      "Imputing row 4501/7414 with 0 missing, elapsed time: 12.522\n",
      "Imputing row 4601/7414 with 0 missing, elapsed time: 12.522\n",
      "Imputing row 4701/7414 with 0 missing, elapsed time: 12.522\n",
      "Imputing row 4801/7414 with 0 missing, elapsed time: 12.523\n",
      "Imputing row 4901/7414 with 0 missing, elapsed time: 12.523\n",
      "Imputing row 5001/7414 with 0 missing, elapsed time: 12.523\n",
      "Imputing row 5101/7414 with 0 missing, elapsed time: 12.523\n",
      "Imputing row 5201/7414 with 0 missing, elapsed time: 12.524\n",
      "Imputing row 5301/7414 with 0 missing, elapsed time: 12.524\n",
      "Imputing row 5401/7414 with 0 missing, elapsed time: 12.524\n",
      "Imputing row 5501/7414 with 0 missing, elapsed time: 12.525\n",
      "Imputing row 5601/7414 with 0 missing, elapsed time: 12.525\n",
      "Imputing row 5701/7414 with 0 missing, elapsed time: 12.525\n",
      "Imputing row 5801/7414 with 0 missing, elapsed time: 12.525\n",
      "Imputing row 5901/7414 with 0 missing, elapsed time: 12.526\n",
      "Imputing row 6001/7414 with 0 missing, elapsed time: 12.526\n",
      "Imputing row 6101/7414 with 0 missing, elapsed time: 12.526\n",
      "Imputing row 6201/7414 with 0 missing, elapsed time: 12.527\n",
      "Imputing row 6301/7414 with 0 missing, elapsed time: 12.527\n",
      "Imputing row 6401/7414 with 0 missing, elapsed time: 12.527\n",
      "Imputing row 6501/7414 with 0 missing, elapsed time: 12.528\n",
      "Imputing row 6601/7414 with 0 missing, elapsed time: 12.528\n",
      "Imputing row 6701/7414 with 0 missing, elapsed time: 12.528\n",
      "Imputing row 6801/7414 with 0 missing, elapsed time: 12.529\n",
      "Imputing row 6901/7414 with 0 missing, elapsed time: 12.529\n",
      "Imputing row 7001/7414 with 0 missing, elapsed time: 12.529\n",
      "Imputing row 7101/7414 with 0 missing, elapsed time: 12.530\n",
      "Imputing row 7201/7414 with 0 missing, elapsed time: 12.530\n",
      "Imputing row 7301/7414 with 0 missing, elapsed time: 12.530\n",
      "Imputing row 7401/7414 with 0 missing, elapsed time: 12.531\n"
     ]
    }
   ],
   "source": [
    "#KNN Complete is replaced by .fit_transform to match the SK_learn \n",
    "\n",
    "#Apply KNN imputation algorithm\n",
    "marketing_train = pd.DataFrame(KNN(k = 3).fit_transform(marketing_train), columns = marketing_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert into proper datatypes\n",
    "\n",
    "#solution for round off error - https://stackoverflow.com/questions/19387608/attributeerror-rint-when-using-numpy-round\n",
    "\n",
    "\n",
    "for i in lis:\n",
    "    marketing_train.loc[:,i] = np.around(marketing_train.loc[:,i].astype(np.double),3)\n",
    "    marketing_train.loc[:,i] = marketing_train.loc[:,i].astype('object')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Outlier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = marketing_train.copy()\n",
    "#marketing_train = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Plot boxplot to visualize Outliers\n",
    "# %matplotlib inline  \n",
    "# plt.boxplot(marketing_train['custAge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type('sds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save numeric names\n",
    "cnames =  [\"custAge\", \"campaign\", \"pdays\", \"previous\", \"emp.var.rate\", \"cons.price.idx\", \"cons.conf.idx\", \"euribor3m\",\n",
    "           \"nr.employed\", \"pmonths\", \"pastEmail\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Detect and delete outliers from data\n",
    "# for i in cnames:\n",
    "#     print(i)\n",
    "#     q75, q25 = np.percentile(marketing_train.loc[:,i], [75 ,25])\n",
    "#     iqr = q75 - q25\n",
    "\n",
    "#     min = q25 - (iqr*1.5)\n",
    "#     max = q75 + (iqr*1.5)\n",
    "#     print(min)\n",
    "#     print(max)\n",
    "    \n",
    "#     marketing_train = marketing_train.drop(marketing_train[marketing_train.loc[:,i] < min].index)\n",
    "#     marketing_train = marketing_train.drop(marketing_train[marketing_train.loc[:,i] > max].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detect and replace with NA\n",
    "# #Extract quartiles\n",
    "# q75, q25 = np.percentile(marketing_train['custAge'], [75 ,25])\n",
    "\n",
    "# #Calculate IQR\n",
    "# iqr = q75 - q25\n",
    "\n",
    "# #Calculate inner and outer fence\n",
    "# minimum = q25 - (iqr*1.5)\n",
    "# maximum = q75 + (iqr*1.5)\n",
    "\n",
    "# #Replace with NA\n",
    "# marketing_train.loc[marketing_train['custAge'] < minimum,:'custAge'] = np.nan\n",
    "# marketing_train.loc[marketing_train['custAge'] > maximum,:'custAge'] = np.nan\n",
    "\n",
    "# #Calculate missing value\n",
    "# missing_val = pd.DataFrame(marketing_train.isnull().sum())\n",
    "\n",
    "# #Impute with KNN\n",
    "# marketing_train = pd.DataFrame(KNN(k = 3).complete(marketing_train), columns = marketing_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Correlation analysis\n",
    "#Correlation plot\n",
    "df_corr = marketing_train.loc[:,cnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a35660a58>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set the width and hieght of the plot\n",
    "f, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "#Generate correlation matrix\n",
    "corr = df_corr.corr()\n",
    "\n",
    "#Plot using seaborn library\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chisquare test of independence\n",
    "#Save categorical variables\n",
    "cat_names = [\"profession\", \"marital\", \"schooling\", \"default\", \"housing\", \"loan\", \"contact\", \"month\", \"day_of_week\", \"poutcome\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profession\n",
      "1.6242589537712605e-34\n",
      "marital\n",
      "4.693435664866768e-05\n",
      "schooling\n",
      "3.0802565674571545e-34\n",
      "default\n",
      "1.626010224096433e-15\n",
      "housing\n",
      "0.5469213692385477\n",
      "loan\n",
      "0.09547438986454948\n",
      "contact\n",
      "4.416434113838791e-36\n",
      "month\n",
      "3.3492292613263237e-139\n",
      "day_of_week\n",
      "2.3175048561931414e-12\n",
      "poutcome\n",
      "3.898575747043989e-181\n"
     ]
    }
   ],
   "source": [
    "#loop for chi square values\n",
    "for i in cat_names:\n",
    "    print(i)\n",
    "    chi2, p, dof, ex = chi2_contingency(pd.crosstab(marketing_train['responded'], marketing_train[i]))\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "marketing_train = marketing_train.drop(['pdays', 'emp.var.rate', 'day_of_week', 'loan', 'housing'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = marketing_train.copy()\n",
    "#marketing_train = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.193e+03, 0.000e+00, 0.000e+00, 0.000e+00, 1.953e+03, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 9.560e+02, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 4.770e+02, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 2.450e+02, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        1.790e+02, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+02,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 6.600e+01, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 6.100e+01, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 3.600e+01, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        3.800e+01, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 2.100e+01,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.400e+01, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 1.300e+01, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 7.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 7.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        8.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 5.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 8.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 4.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 2.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 4.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 2.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 4.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 2.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        2.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00]),\n",
       " array([ 1.        ,  1.20418848,  1.40837696,  1.61256545,  1.81675393,\n",
       "         2.02094241,  2.22513089,  2.42931937,  2.63350785,  2.83769634,\n",
       "         3.04188482,  3.2460733 ,  3.45026178,  3.65445026,  3.85863874,\n",
       "         4.06282723,  4.26701571,  4.47120419,  4.67539267,  4.87958115,\n",
       "         5.08376963,  5.28795812,  5.4921466 ,  5.69633508,  5.90052356,\n",
       "         6.10471204,  6.30890052,  6.51308901,  6.71727749,  6.92146597,\n",
       "         7.12565445,  7.32984293,  7.53403141,  7.7382199 ,  7.94240838,\n",
       "         8.14659686,  8.35078534,  8.55497382,  8.7591623 ,  8.96335079,\n",
       "         9.16753927,  9.37172775,  9.57591623,  9.78010471,  9.98429319,\n",
       "        10.18848168, 10.39267016, 10.59685864, 10.80104712, 11.0052356 ,\n",
       "        11.20942408, 11.41361257, 11.61780105, 11.82198953, 12.02617801,\n",
       "        12.23036649, 12.43455497, 12.63874346, 12.84293194, 13.04712042,\n",
       "        13.2513089 , 13.45549738, 13.65968586, 13.86387435, 14.06806283,\n",
       "        14.27225131, 14.47643979, 14.68062827, 14.88481675, 15.08900524,\n",
       "        15.29319372, 15.4973822 , 15.70157068, 15.90575916, 16.10994764,\n",
       "        16.31413613, 16.51832461, 16.72251309, 16.92670157, 17.13089005,\n",
       "        17.33507853, 17.53926702, 17.7434555 , 17.94764398, 18.15183246,\n",
       "        18.35602094, 18.56020942, 18.76439791, 18.96858639, 19.17277487,\n",
       "        19.37696335, 19.58115183, 19.78534031, 19.9895288 , 20.19371728,\n",
       "        20.39790576, 20.60209424, 20.80628272, 21.0104712 , 21.21465969,\n",
       "        21.41884817, 21.62303665, 21.82722513, 22.03141361, 22.23560209,\n",
       "        22.43979058, 22.64397906, 22.84816754, 23.05235602, 23.2565445 ,\n",
       "        23.46073298, 23.66492147, 23.86910995, 24.07329843, 24.27748691,\n",
       "        24.48167539, 24.68586387, 24.89005236, 25.09424084, 25.29842932,\n",
       "        25.5026178 , 25.70680628, 25.91099476, 26.11518325, 26.31937173,\n",
       "        26.52356021, 26.72774869, 26.93193717, 27.13612565, 27.34031414,\n",
       "        27.54450262, 27.7486911 , 27.95287958, 28.15706806, 28.36125654,\n",
       "        28.56544503, 28.76963351, 28.97382199, 29.17801047, 29.38219895,\n",
       "        29.58638743, 29.79057592, 29.9947644 , 30.19895288, 30.40314136,\n",
       "        30.60732984, 30.81151832, 31.01570681, 31.21989529, 31.42408377,\n",
       "        31.62827225, 31.83246073, 32.03664921, 32.2408377 , 32.44502618,\n",
       "        32.64921466, 32.85340314, 33.05759162, 33.2617801 , 33.46596859,\n",
       "        33.67015707, 33.87434555, 34.07853403, 34.28272251, 34.48691099,\n",
       "        34.69109948, 34.89528796, 35.09947644, 35.30366492, 35.5078534 ,\n",
       "        35.71204188, 35.91623037, 36.12041885, 36.32460733, 36.52879581,\n",
       "        36.73298429, 36.93717277, 37.14136126, 37.34554974, 37.54973822,\n",
       "        37.7539267 , 37.95811518, 38.16230366, 38.36649215, 38.57068063,\n",
       "        38.77486911, 38.97905759, 39.18324607, 39.38743455, 39.59162304,\n",
       "        39.79581152, 40.        ]),\n",
       " <a list of 191 Patch objects>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Normality check\n",
    "%matplotlib inline  \n",
    "plt.hist(marketing_train['campaign'], bins='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnames = [\"custAge\",\"campaign\",\"previous\",\"cons.price.idx\",\"cons.conf.idx\",\"euribor3m\",\"nr.employed\",\n",
    "           \"pmonths\",\"pastEmail\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custAge\n",
      "campaign\n",
      "previous\n",
      "cons.price.idx\n",
      "cons.conf.idx\n",
      "euribor3m\n",
      "nr.employed\n",
      "pmonths\n",
      "pastEmail\n"
     ]
    }
   ],
   "source": [
    "#Nomalisation\n",
    "for i in cnames:\n",
    "    print(i)\n",
    "    marketing_train[i] = (marketing_train[i] - min(marketing_train[i]))/(max(marketing_train[i]) - min(marketing_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Standarisation\n",
    "# for i in cnames:\n",
    "#     print(i)\n",
    "#     marketing_train[i] = (marketing_train[i] - marketing_train[i].mean())/marketing_train[i].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Simple random sampling\n",
    "#Sim_Sampling = marketing_train.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##Systematic Sampling\n",
    "# #Calculate the K value\n",
    "# k = len(marketing_train)/3500\n",
    "\n",
    "# # Generate a random number using simple random sampling\n",
    "# RandNum = randrange(0, 5)\n",
    "\n",
    "# #select Kth observation starting from RandNum\n",
    "# Sys_Sampling = marketing_train.iloc[RandNum::k, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Stratified sampling\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# #Select categorical variable\n",
    "# y = marketing_train['profession']\n",
    "\n",
    "#select subset using stratified Sampling\n",
    "#Rest, Sample = train_test_split(marketing_train, test_size = 0.6, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#marketing_train = pd.read_csv(\"marketing_train_Model.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.cross_validation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-b08853276edb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.cross_validation'"
     ]
    }
   ],
   "source": [
    "#Import Libraries for decision tree\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace target categories with Yes or No\n",
    "marketing_train['responded'] = marketing_train['responded'].replace(0, 'No')\n",
    "marketing_train['responded'] = marketing_train['responded'].replace(1, 'Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide data into train and test\n",
    "X = marketing_train.values[:, 0:16]\n",
    "Y = marketing_train.values[:,16]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "C50_model = tree.DecisionTreeClassifier(criterion='entropy').fit(X_train, y_train)\n",
    "\n",
    "#predict new test cases\n",
    "C50_Predictions = C50_model.predict(X_test)\n",
    "\n",
    "#Create dot file to visualise tree  #http://webgraphviz.com/\n",
    "# dotfile = open(\"pt.dot\", 'w')\n",
    "# df = tree.export_graphviz(C50_model, out_file=dotfile, feature_names = marketing_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build confusion matrix\n",
    "# from sklearn.metrics import confusion_matrix \n",
    "# CM = confusion_matrix(y_test, y_pred)\n",
    "CM = pd.crosstab(y_test, C50_Predictions)\n",
    "\n",
    "#let us save TP, TN, FP, FN\n",
    "TN = CM.iloc[0,0]\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FP = CM.iloc[0,1]\n",
    "\n",
    "#check accuracy of model\n",
    "#accuracy_score(y_test, y_pred)*100\n",
    "((TP+TN)*100)/(TP+TN+FP+FN)\n",
    "\n",
    "#False Negative rate \n",
    "#(FN*100)/(FN+TP)\n",
    "\n",
    "#Results\n",
    "#Accuracy: 84.49\n",
    "#FNR: 63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF_model = RandomForestClassifier(n_estimators = 20).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_Predictions = RF_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build confusion matrix\n",
    "# from sklearn.metrics import confusion_matrix \n",
    "# CM = confusion_matrix(y_test, y_pred)\n",
    "CM = pd.crosstab(y_test, RF_Predictions)\n",
    "\n",
    "#let us save TP, TN, FP, FN\n",
    "TN = CM.iloc[0,0]\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FP = CM.iloc[0,1]\n",
    "\n",
    "#check accuracy of model\n",
    "#accuracy_score(y_test, y_pred)*100\n",
    "((TP+TN)*100)/(TP+TN+FP+FN)\n",
    "\n",
    "#False Negative rate \n",
    "#(FN*100)/(FN+TP)\n",
    "\n",
    "#Accuracy: 88\n",
    "#FNR: 67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us prepare data for logistic regression\n",
    "#replace target categories with Yes or No\n",
    "marketing_train['responded'] = marketing_train['responded'].replace('No', 0)\n",
    "marketing_train['responded'] = marketing_train['responded'].replace('Yes', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create logistic data. Save target variable first\n",
    "marketing_train_logit = pd.DataFrame(marketing_train['responded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add continous variables\n",
    "marketing_train_logit = marketing_train_logit.join(marketing_train[cnames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marketing_train_logit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create dummies for categorical variables\n",
    "cat_names = [\"profession\", \"marital\", \"schooling\", \"default\", \"contact\", \"month\", \"poutcome\"]\n",
    "\n",
    "for i in cat_names:\n",
    "    temp = pd.get_dummies(marketing_train[i], prefix = i)\n",
    "    marketing_train_logit = marketing_train_logit.join(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample_Index = np.random.rand(len(marketing_train_logit)) < 0.8\n",
    "\n",
    "train = marketing_train_logit[Sample_Index]\n",
    "test = marketing_train_logit[~Sample_Index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#select column indexes for independent variables\n",
    "train_cols = train.columns[1:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Built Logistic Regression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "logit = sm.Logit(train['responded'], train[train_cols]).fit()\n",
    "\n",
    "logit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Predict test data\n",
    "test['Actual_prob'] = logit.predict(test[train_cols])\n",
    "\n",
    "test['ActualVal'] = 1\n",
    "test.loc[test.Actual_prob < 0.5, 'ActualVal'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build confusion matrix\n",
    "CM = pd.crosstab(test['responded'], test['ActualVal'])\n",
    "\n",
    "#let us save TP, TN, FP, FN\n",
    "TN = CM.iloc[0,0]\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FP = CM.iloc[0,1]\n",
    "\n",
    "#check accuracy of model\n",
    "#accuracy_score(y_test, y_pred)*100\n",
    "((TP+TN)*100)/(TP+TN+FP+FN)\n",
    "\n",
    "(FN*100)/(FN+TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Accuracy: 90\n",
    "#FNR: 74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#KNN implementation\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "KNN_model = KNeighborsClassifier(n_neighbors = 9).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predict test cases\n",
    "KNN_Predictions = KNN_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build confusion matrix\n",
    "CM = pd.crosstab(y_test, KNN_Predictions)\n",
    "\n",
    "#let us save TP, TN, FP, FN\n",
    "TN = CM.iloc[0,0]\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FP = CM.iloc[0,1]\n",
    "\n",
    "#check accuracy of model\n",
    "#accuracy_score(y_test, y_pred)*100\n",
    "((TP+TN)*100)/(TP+TN+FP+FN)\n",
    "\n",
    "#False Negative rate \n",
    "(FN*100)/(FN+TP)\n",
    "\n",
    "#Accuracy: 89\n",
    "#FNR: 76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Naive Bayes implementation\n",
    "NB_model = GaussianNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predict test cases\n",
    "NB_Predictions = NB_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build confusion matrix\n",
    "CM = pd.crosstab(y_test, NB_Predictions)\n",
    "\n",
    "#let us save TP, TN, FP, FN\n",
    "TN = CM.iloc[0,0]\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FP = CM.iloc[0,1]\n",
    "\n",
    "#check accuracy of model\n",
    "#accuracy_score(y_test, y_pred)*100\n",
    "#((TP+TN)*100)/(TP+TN+FP+FN)\n",
    "\n",
    "#False Negative rate \n",
    "(FN*100)/(FN+TP)\n",
    "\n",
    "#Accuracy: 81\n",
    "#FNR: 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "df = pd.read_csv(\"df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load required libraries\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#Estimate optimum number of clusters\n",
    "cluster_range = range( 1, 20 )\n",
    "cluster_errors = []\n",
    "\n",
    "for num_clusters in cluster_range:\n",
    "    clusters = KMeans(num_clusters).fit(df.iloc[:,0:4])\n",
    "    cluster_errors.append(clusters.inertia_)\n",
    "    \n",
    "#Create dataframe with cluster errors\n",
    "clusters_df = pd.DataFrame( { \"num_clusters\":cluster_range, \"cluster_errors\": cluster_errors } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot line chart to visualise number of clusters\n",
    "%matplotlib inline  \n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot( clusters_df.num_clusters, clusters_df.cluster_errors, marker = \"o\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Implement kmeans\n",
    "kmeans_model = KMeans(n_clusters = 3).fit(df.iloc[:,0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summarize output\n",
    "pd.crosstab(df['Species'], kmeans_model.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_range = range( 1, 20 )\n",
    "cluster_errors = []\n",
    "\n",
    "for num_clusters in cluster_range:\n",
    "    clusters = KMeans( num_clusters )\n",
    "    clusters.fit( df.iloc[:,0:4] )\n",
    "    cluster_errors.append( clusters.inertia_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusters_df = pd.DataFrame( { \"num_clusters\":cluster_range, \"cluster_errors\": cluster_errors } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot( clusters_df.num_clusters, clusters_df.cluster_errors, marker = \"o\" )"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
